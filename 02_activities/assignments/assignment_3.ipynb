{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b0bcac6-5086-4f4e-928a-570a9ff7ae58",
   "metadata": {},
   "source": [
    "# Assignment 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fce0350-2a17-4e93-8d4c-0b8748fdfc32",
   "metadata": {},
   "source": [
    "You only need to write one line of code for each question. When answering questions that ask you to identify or interpret something, the length of your response doesnâ€™t matter. For example, if the answer is just â€˜yes,â€™ â€˜no,â€™ or a number, you can just give that answer without adding anything else.\n",
    "\n",
    "We will go through comparable code and concepts in the live learning session. If you run into trouble, start by using the help `help()` function in Python, to get information about the datasets and function in question. The internet is also a great resource when coding (though note that **no outside searches are required by the assignment!**). If you do incorporate code from the internet, please cite the source within your code (providing a URL is sufficient).\n",
    "\n",
    "Please bring questions that you cannot work out on your own to office hours, work periods or share with your peers on Slack. We will work with you through the issue."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc5001c-7715-4ebe-b0f7-e4bd04349629",
   "metadata": {},
   "source": [
    "### Clustering and Resampling\n",
    "\n",
    "Let's set up our workspace and use the **Iris dataset** from `scikit-learn`. This dataset is a classic dataset in machine learning and statistics, widely used for clustering tasks. It consists of many samples of iris flowers. Here are the key features and characteristics of the dataset:\n",
    "\n",
    "##### Features:\n",
    "1. **Sepal Length**: The length of the sepal in centimeters.\n",
    "2. **Sepal Width**: The width of the sepal in centimeters.\n",
    "3. **Petal Length**: The length of the petal in centimeters.\n",
    "4. **Petal Width**: The width of the petal in centimeters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a3485d6-ba58-4660-a983-5680821c5719",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import standard libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3491d919",
   "metadata": {},
   "source": [
    "#### **Question 1:** \n",
    "#### Data inspection\n",
    "\n",
    "#### Load the Iris dataset:\n",
    "\n",
    "Use scikit-learn to load the Iris dataset and convert it into a Pandas DataFrame.\n",
    "Display the first few rows of the dataset. How many observations (rows) and features (columns) does the dataset contain?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a431d282-f9ca-4d5d-8912-71ffc9d8ea19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import standard libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "# Load the Iris dataset\n",
    "iris_data = load_iris()\n",
    "\n",
    "# Convert to DataFrame\n",
    "iris_df = pd.DataFrame(iris_data.data, columns=iris_data.feature_names)\n",
    "\n",
    "# Bind the disease progression (diabetes target) to the DataFrame\n",
    "iris_df['species'] = iris_data.target\n",
    "\n",
    "\n",
    "# Display the DataFrame\n",
    "print(iris_df)\n",
    "\n",
    "#Your code here ... \n",
    "\n",
    "print(iris_df.head())\n",
    "print(iris_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3832d7",
   "metadata": {},
   "source": [
    "#### **Question 2:** \n",
    "#### Data-visualization\n",
    "\n",
    "Let's create plots to visualize the relationships between the features (sepal length, sepal width, petal length, petal width).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd6dc0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_pairs(data, feature_names, color_labels=None, title_prefix=''):\n",
    "    \"\"\"\n",
    "    Helper function to create scatter plots for all possible pairs of features.\n",
    "    \n",
    "    Parameters:\n",
    "    - data: DataFrame containing the features to be plotted.\n",
    "    - feature_names: List of feature names to be used in plotting.\n",
    "    - color_labels: Optional. Cluster or class labels to color the scatter plots.\n",
    "    - title_prefix: Optional. Prefix for plot titles to distinguish between different sets of plots.\n",
    "    \"\"\"\n",
    "    # Create a figure for the scatter plots\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    \n",
    "    # Counter for subplot index\n",
    "    plot_number = 1\n",
    "    \n",
    "    # Loop through each pair of features\n",
    "    for i in range(len(feature_names)):\n",
    "        for j in range(i + 1, len(feature_names)):\n",
    "            plt.subplot(len(feature_names)-1, len(feature_names)-1, plot_number)\n",
    "            \n",
    "            # Scatter plot colored by labels if provided\n",
    "            if color_labels is not None:\n",
    "                plt.scatter(data[feature_names[i]], data[feature_names[j]], \n",
    "                            c=color_labels, cmap='viridis', alpha=0.7)\n",
    "            else:\n",
    "                plt.scatter(data[feature_names[i]], data[feature_names[j]], alpha=0.7)\n",
    "            \n",
    "            plt.xlabel(feature_names[i])\n",
    "            plt.ylabel(feature_names[j])\n",
    "            plt.title(f'{title_prefix}{feature_names[i]} vs {feature_names[j]}')\n",
    "            \n",
    "            # Increment the plot number\n",
    "            plot_number += 1\n",
    "\n",
    "    # Adjust layout to prevent overlap\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n",
    "# Get feature names\n",
    "feature_names = iris_df.columns\n",
    "\n",
    "# Use the helper function to plot scatter plots without coloring by cluster labels\n",
    "plot_feature_pairs(iris_df, feature_names, title_prefix='Original Data: ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9701cd4",
   "metadata": {},
   "source": [
    "**Question:**\n",
    "- Do you notice any patterns or relationships between the different features? How might these patterns help in distinguishing between different species?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35308e2c",
   "metadata": {},
   "source": [
    "> Your answer...\n",
    "\n",
    "The scatter plots reveal noticeable patterns between certain features. For instance, petal length and petal width show a clear positive relationship, where data points form distinct clusters. This suggests these features could be useful in differentiating between groups. In contrast, sepal length and sepal width display weaker relationships, meaning they might not be as effective in distinguishing categories.\n",
    "\n",
    "These patterns indicate that some features, such as petal measurements are more valuable than others when it comes to identifying groups or clusters. Understanding these relationships can help in feature selection and improve the effectiveness of clustering or classification algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d596b3af",
   "metadata": {},
   "source": [
    "#### **Question 3:** \n",
    "#### Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2cfec72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Scale all the features in the dataset\n",
    "scaled_features = scaler.fit_transform(iris_df)\n",
    "\n",
    "# Create a new DataFrame with scaled features\n",
    "scaled_iris_df = pd.DataFrame(scaled_features, columns=iris_data.feature_names)\n",
    "\n",
    "# Display the first few rows of the scaled DataFrame\n",
    "print(scaled_iris_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035fa019",
   "metadata": {},
   "source": [
    "Why is it important to standardize the features of a dataset before applying clustering algorithms like K-Means? Discuss the implications of using unstandardized data in your analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d77d5c",
   "metadata": {},
   "source": [
    "> Your answer here ... \n",
    "\n",
    "Since clustering algorithms rely on distance calculations, features with larger scales can dominate the process if they are not standardized. This can result in biased clustering, where certain features disproportionately influence the outcome. Standardizing ensures that all features are on a similar scale, typically with a mean of 0 and a standard deviation of 1, so they contribute equally to the analysis. Without standardization, the algorithm might give undue weight to features with larger numerical ranges, skewing the clustering results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4604ee03",
   "metadata": {},
   "source": [
    "#### **Question 4:** \n",
    "#### K-means clustering \n",
    "\n",
    "Apply the K-Means clustering algorithm to the Iris dataset. Choose the value 3 for the number of clusters (`k=3`) and fit the model. Assign cluster labels to the original data and add them as a new column in the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909df219",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import standard libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris_data = load_iris()\n",
    "\n",
    "# Convert to DataFrame\n",
    "iris_df = pd.DataFrame(iris_data.data, columns=iris_data.feature_names)\n",
    "\n",
    "# Initialize the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Scale the features (excluding the species column)\n",
    "scaled_features = scaler.fit_transform(iris_df)\n",
    "\n",
    "# Create a new DataFrame with scaled features\n",
    "scaled_iris_df = pd.DataFrame(scaled_features, columns=iris_data.feature_names)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Your code here ...\n",
    "\n",
    "\n",
    "# Apply K-Means with k=3\n",
    "kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "iris_df['Cluster'] = kmeans.fit_predict(iris_df)\n",
    "\n",
    "# Create a copy for clustered data\n",
    "clustered_iris_data = iris_df.copy()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Use the helper function to plot scatter plots, colored by cluster labels\n",
    "plot_feature_pairs(clustered_iris_data, iris_data.feature_names, color_labels=clustered_iris_data['Cluster'], title_prefix='Clustered Data: ')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46914737",
   "metadata": {},
   "source": [
    "We chose `k=3` for the number of clusters arbitrarily. However, in a real-world scenario, it is important to determine the optimal number of clusters using appropriate methods.\n",
    "\n",
    "**Question**: What is one method commonly used to determine the optimal number of clusters in K-means clustering, and why is this method helpful?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83349688",
   "metadata": {},
   "source": [
    "> Your answer here...\n",
    "\n",
    "The results of the K-Means clustering on the Iris dataset can be evaluated by comparing the assigned clusters to the true species labels. Typically, Cluster 0 contains all 50 samples of Iris setosa, indicating a perfect match. Clusters 1 and 2 often overlap between Iris versicolor and Iris virginica, revealing some ambiguity. For instance, Cluster 1 might include 30 Iris versicolor and 18 Iris virginica, yielding a purity of 62.5%, while Cluster 2 could consist of 40 Iris virginica and 12 Iris versicolor, resulting in a purity of 76.9%.\n",
    "\n",
    "Visualization through scatter plots usually shows a clear separation for Iris setosa, but Iris versicolor and Iris virginica may overlap, indicating that the feature distributions do not fully distinguish between these two species. Overall, while K-Means clustering effectively identifies Iris setosa, it faces challenges in differentiating Iris versicolor from Iris virginica. Metrics like purity provide quantitative insights into clustering performance, highlighting the need for improved feature selection or the exploration of alternative clustering algorithms.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6bc2f4f",
   "metadata": {},
   "source": [
    "#### **Question 5:** \n",
    "#### Bootstrapping \n",
    "\n",
    "Implement bootstrapping on the mean of Petal Width. Generate 10000 bootstrap samples, calculate the mean for each sample, and compute a 90% confidence interval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4c4011",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris_data = load_iris()\n",
    "iris_df = pd.DataFrame(data=iris_data.data, columns=iris_data.feature_names)\n",
    "\n",
    "# Set the random seed for reproducibility\n",
    "np.random.seed(123)\n",
    "\n",
    "# Define the number of bootstrap samples\n",
    "n_bootstrap_samples = 10000\n",
    "\n",
    "# Create an array to store the means of each bootstrap sample\n",
    "bootstrap_means = np.empty(n_bootstrap_samples)\n",
    "\n",
    "# Perform bootstrapping on the mean of Petal Width\n",
    "for i in range(n_bootstrap_samples):\n",
    "    # Generate a bootstrap sample by randomly sampling with replacement\n",
    "    bootstrap_sample = iris_df['petal width (cm)'].sample(frac=1, replace=True)  # Use the correct column name\n",
    "    \n",
    "    # Calculate and store the mean of the bootstrap sample\n",
    "    bootstrap_means[i] = bootstrap_sample.mean()\n",
    "\n",
    "# Calculate the overall mean of petal width\n",
    "mean_petal_width = np.mean(bootstrap_means)\n",
    "\n",
    "# Calculate the 90% confidence interval (5th and 95th percentiles)\n",
    "lower_bound = np.percentile(bootstrap_means, 5)\n",
    "upper_bound = np.percentile(bootstrap_means, 95)\n",
    "\n",
    "\n",
    "# Display the result\n",
    "print(f\"Mean of Petal Width: {mean_petal_width}\")\n",
    "print(f\"90% Confidence Interval of Mean Petal Width: ({lower_bound}, {upper_bound})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f73843",
   "metadata": {},
   "source": [
    "**Question:**\n",
    "- Why do we use bootstrapping in this context? What does it help us understand about the mean?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a6e104",
   "metadata": {},
   "source": [
    ">  Your answer...\n",
    "\n",
    "Bootstrapping is used to estimate the sampling distribution of the mean by resampling the data with replacement. Since we don't know the true population distribution, bootstrapping helps approximate it by generating many new samples from the existing data. This gives a distribution of sample means, allowing us to assess the variability of the mean. The 90% confidence interval helps us understand the range in which the true mean is likely to fall, providing a better sense of the reliability of the estimate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0741b2ca",
   "metadata": {},
   "source": [
    "**Question:**\n",
    "- What is the purpose of calculating the confidence interval from the bootstrap samples? How does it help us interpret the variability of the estimate?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5be82ec",
   "metadata": {},
   "source": [
    "> Your answer...\n",
    "\n",
    "Calculating the confidence interval from bootstrap samples helps us understand the variability and reliability of our estimateâ€”in this case, the mean of Petal Width. By resampling the data multiple times, we simulate different possible outcomes, allowing us to see how much the mean might fluctuate. The confidence interval provides a range where we expect the true population mean to fall with a certain level of confidence. It helps quantify the uncertainty around the estimate based on the data we have."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29096311",
   "metadata": {},
   "source": [
    "**Question:**\n",
    "\n",
    "- Reflect on the variability observed in the bootstrapped means and discuss whether the mean of the Petal Width appears to be a stable and reliable estimate based on the confidence interval and the spread of the bootstrapped means."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7e6778",
   "metadata": {},
   "source": [
    "> Your answer here...\n",
    "\n",
    "The variability in the bootstrapped means shows how much the estimate of Petal Width fluctuates across different samples. If the spread of the bootstrapped means is narrow and the confidence interval is small, the mean appears to be stable and reliable. A wider spread or larger confidence interval would suggest more uncertainty and less reliability in the estimate. In this case, the confidence interval helps confirm whether the mean of Petal Width is a consistent measure across various resampled datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f8a69db",
   "metadata": {},
   "source": [
    "# Criteria\n",
    "\n",
    "\n",
    "| **Criteria**                                           | **Complete**                                      | **Incomplete**                                    |\n",
    "|--------------------------------------------------------|---------------------------------------------------|--------------------------------------------------|\n",
    "| **Data Inspection**                                    | Data is thoroughly inspected for the number of variables, observations, and data types, and relevant insights are noted. | Data inspection is missing or lacks detail.         |\n",
    "| **Data Visualization**                                 | Visualizations (e.g., scatter plots) are well-constructed and correctly interpreted to explore relationships between features and species. | Visualizations are poorly constructed or not correctly interpreted. |\n",
    "| **Clustering Implementation**                           | K-Means clustering is correctly implemented, and cluster labels are appropriately assigned to the dataset.            | K-Means clustering is missing or incorrectly implemented. |\n",
    "| **Bootstrapping Process**                              | Bootstrapping is correctly performed, and results are used to assess variable mean stability. | Bootstrapping is missing or incorrectly performed. |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b4390cc",
   "metadata": {},
   "source": [
    "## Submission Information\n",
    "\n",
    "ðŸš¨ **Please review our [Assignment Submission Guide](https://github.com/UofT-DSI/onboarding/blob/main/onboarding_documents/submissions.md)** ðŸš¨ for detailed instructions on how to format, branch, and submit your work. Following these guidelines is crucial for your submissions to be evaluated correctly.\n",
    "\n",
    "### Note:\n",
    "\n",
    "If you like, you may collaborate with others in the cohort. If you choose to do so, please indicate with whom you have worked with in your pull request by tagging their GitHub username. Separate submissions are required.\n",
    "\n",
    "### Submission Parameters:\n",
    "* Submission Due Date: `HH:MM AM/PM - DD/MM/YYYY`\n",
    "* The branch name for your repo should be: `assignment-3`\n",
    "* What to submit for this assignment:\n",
    "    * This Jupyter Notebook (assignment_1.ipynb) should be populated and should be the only change in your pull request.\n",
    "* What the pull request link should look like for this assignment: `https://github.com/<your_github_username>/applying_statistical_concepts/pull/<pr_id>`\n",
    "    * Open a private window in your browser. Copy and paste the link to your pull request into the address bar. Make sure you can see your pull request properly. This helps the technical facilitator and learning support staff review your submission easily.\n",
    "\n",
    "Checklist:\n",
    "- [ ] Created a branch with the correct naming convention.\n",
    "- [ ] Ensured that the repository is public.\n",
    "- [ ] Reviewed the PR description guidelines and adhered to them.\n",
    "- [ ] Verify that the link is accessible in a private browser window.\n",
    "\n",
    "If you encounter any difficulties or have questions, please don't hesitate to reach out to our team via our Slack at `#cohort-4-help`. Our Technical Facilitators and Learning Support staff are here to help you navigate any challenges.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "vscode": {
   "interpreter": {
    "hash": "497a84dc8fec8cf8d24e7e87b6d954c9a18a327edc66feb9b9ea7e9e72cc5c7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
